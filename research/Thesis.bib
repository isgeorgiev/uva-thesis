@article{Dogan2014,
abstract = {BioC is a recently created XML format to share text data and annotations, and an accompanying input/output library to promote interoperability of data and tools for natural language processing of biomedical text. This article reports the use of BioC to address a common challenge in processing biomedical text information that of frequent entity name abbreviation. We selected three different abbreviation definition identification modules, and used the publicly available BioC code to convert these independent modules into BioC-compatible components that interact seamlessly with BioC-formatted data, and other BioC-compatible modules. In addition, we consider four manually annotated corpora of abbreviations in biomedical text: the Ab3P corpus of 1250 PubMed abstracts, the BIOADI corpus of 1201 PubMed abstracts, the old MEDSTRACT corpus of 199 PubMedVR citations and the Schwartz and Hearst corpus of 1000 PubMed abstracts. Annotations in these corpora have been re-evaluated by four annotators and their consistency and quality levels have been improved. We converted them to BioC-format and described the representation of the annotations. These corpora are used to measure the three abbreviation-finding algorithms and the results are given. The BioC-compatible modules, when compared with their original form, have no difference in their efficiency, running time or any other comparable aspects. They can be conveniently used as a common pre-processing step for larger multi-layered text-mining endeavors.},
author = {Doǧan, Rezarta Islamaj and Comeau, Donald C. and Yeganova, Lana and Wilbur, W. J.},
doi = {10.1093/database/bau044},
file = {:D\:/University/Thesis/uva-thesis-repository/research/Finding abbreviations in biomedical literature three BioC-compatible modules and four BioC-formatted corpora.pdf:pdf},
issn = {17580463},
journal = {Database},
pages = {1--7},
pmid = {24914232},
title = {{Finding abbreviations in biomedical literature: three BioC-compatible modules and four BioC-formatted corpora}},
volume = {2014},
year = {2014}
}
@article{Krippendorff2011,
author = {Krippendorff, Klaus},
file = {:D\:/University/Thesis/uva-thesis-repository/research/Computing Krippendorff's Alpha-Reliability.pdf:pdf},
title = {{ScholarlyCommons Computing Krippendorff ' s Alpha-Reliability Computing Krippendorff ' s Alpha-Reliability}},
year = {2011}
}
@article{BenVeyseh2021,
abstract = {Acronyms are the short forms of longer phrases and they are frequently used in writing, especially scholarly writing, to save space and facilitate the communication of information. As such, every text understanding tool should be capable of recognizing acronyms in text (i.e., acronym identification) and also finding their correct meaning (i.e., acronym disambiguation). As most of the prior works on these tasks are restricted to the biomedical domain and use unsupervised methods or models trained on limited datasets, they fail to perform well for scientific document understanding. To push forward research in this direction, we have organized two shared task for acronym identification and acronym disambiguation in scientific documents, named AI@SDU and AD@SDU, respectively. The two shared tasks have attracted 52 and 43 participants, respectively. While the submitted systems make substantial improvements compared to the existing baselines, there are still far from the human-level performance. This paper reviews the two shared tasks and the prominent participating systems for each of them.},
archivePrefix = {arXiv},
arxivId = {2012.11760},
author = {{Ben Veyseh}, Amir Pouran and Dernoncourt, Franck and Nguyen, Thien Huu and Chang, Walter and Celi, Leo Anthony},
eprint = {2012.11760},
file = {:D\:/University/Thesis/uva-thesis-repository/research/Acronym Identification and Disambiguation Shared Tasks for Scientific Document Understanding.pdf:pdf},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
title = {{Acronym identification and disambiguation shared tasks for scientific document understanding}},
volume = {2831},
year = {2021}
}
@article{Zhao2018,
author = {Zhao, Xinshu and Kong, Hong and Feng, Guangchao Charles},
file = {:D\:/University/Thesis/uva-thesis-repository/research/We agreed to measure agreement - Redefining reliability de-justifies Krippendorff 's alpha.pdf:pdf},
keywords = {aggregate estimation,agreement,classification,cohen,human information,individual,individual prediction,inter-coder reliability,inter-rater reliability,krippendorff,mechanical information,multi-concepts,multi-signification,multi-signified,multi-signifiers,multi-signs,reliability,s alpha,s kappa,s pi,scott,selective spiral,sensitivity,specificity,spiral of inertia},
pages = {1--15},
title = {{HKBU Institutional Repository We agreed to measure agreement - Redefining reliability de-justifies Krippendorff ' s alpha We Agreed to Measure Agreement – Redefining Reliability De-justifies Krippendorff ' s Alpha}},
volume = {14},
year = {2018}
}
@article{Passonneau2006,
abstract = {Annotation projects dealing with complex semantic or pragmatic phenomena face the dilemma of creating annotation schemes that oversimplify the phenomena, or that capture distinctions conventional reliability metrics cannot measure adequately. The solution to the dilemma is to develop metrics that quantify the decisions that annotators are asked to make. This paper discusses MASI, distance metric for comparing sets, and illustrates its use in quantifying the reliability of a specific dataset. Annotations of Summary Content Units (SCUs) generate models referred to as pyramids which can be used to evaluate unseen human summaries or machine summaries. The paper presents reliability results for five pairs of pyramids created for document sets from the 2003 Document Understanding Conference (DUC). The annotators worked independently of each other. Differences between application of MASI to pyramid annotation and its previous application to co-reference annotation are discussed. In addition, it is argued that a paradigmatic reliability study should relate measures of inter-annotator agreement to independent assessments, such as significance tests of the annotated variables with respect to other phenomena. In effect, what counts as sufficiently reliable intera-annotator agreement depends on the use the annotated data will be put to.},
author = {Passonneau, Rebecca},
file = {:D\:/University/Thesis/uva-thesis-repository/research/Measuring Agreement on Set-valued Items (MASI) for Semantic and Pragmatic Annotation.pdf:pdf},
journal = {Proceedings of the 5th International Conference on Language Resources and Evaluation, LREC 2006},
pages = {831--836},
title = {{Measuring agreement on set-valued items (MASI) for semantic and pragmatic annotation}},
year = {2006}
}
@article{Joao2022,
abstract = {In this information-accumulating world, each of us must learn continuously. To participate in a new field, or even a sub-field, one must be aware of the terminology including the acronyms that specialists know so well, but newcomers do not. Building on state-of-the art acronym tools, our end-to-end acronym expander system called AcX takes a document, identifies its acronyms, and suggests expansions that are either found in the document or appropriate given the subject matter of the document. As far as we know, AcX is the first open source and extensible system for acronym expansion that allows mixing and matching of different inference modules. As of now, AcX works for English, French, and Portuguese with other languages in progress. This paper describes the design and implementation of AcX, proposes three new acronym expansion benchmarks, compares state-of-the-art techniques on them, and proposes ensemble techniques that improve on any single technique. Finally, the paper evaluates the performance of AcX and related work MadDog system in end-to-end experiments on a new human-annotated dataset of Wikipedia documents. Our experiments show that AcX outperforms MadDog but that human performance is still substantially better than the best automated approaches. Thus, achieving Acronym Expansion at a human level is still a rich and open challenge.},
author = {Jo{\~{a}}o, Jo{\~{a}}o L.M. and Casanova, Jo{\~{a}}o and Galhardas, Helena and Shasha, Dennis},
doi = {10.14778/3551793.3551812},
file = {:D\:/University/Thesis/uva-thesis-repository/research/AcX System, Techniques, and Experiments for Acronym Expansion.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
number = {11},
pages = {2530--2544},
title = {{AcX: System, Techniques, and Experiments for Acronym Expansion}},
volume = {15},
year = {2022}
}
@article{Ao2005,
abstract = {Objective: To help biomedical researchers recognize dynamically introduced abbreviations in biomedical literature, such as gene and protein names, we have constructed a support system called ALICE (Abbreviation LIfter using Corpus-based Extraction). ALICE aims to extract all types of abbreviations with their expansions from a target paper on the fly. Methods: ALICE extracts an abbreviation and its expansion from the literature by using heuristic pattern-matching rules. This system consists of three phases and potentially identifies valid 320 abbreviation-expansion patterns as combinations of the rules. Results: It achieved 95% recall and 97% precision on randomly selected titles and abstracts from the MEDLINE database. Conclusion: ALICE extracted abbreviations and their expansions from the literature efficiently. The subtly compiled heuristics enabled it to extract abbreviations with high recall without significantly reducing precision. ALICE does not only facilitate recognition of an undefined abbreviation in a paper by constructing an abbreviation database or dictionary, but also makes biomedical literature retrieval more accurate. This system is freely available at http://uvdb3.hgc.jp/ALICE/ALICE_index.html.},
author = {Ao, Hiroko and Takagi, Toshihisa},
doi = {10.1197/jamia.M1757},
file = {:D\:/University/Thesis/uva-thesis-repository/research/ALICE An Algorithm to Extract Abbreviations from MEDLINE.pdf:pdf},
issn = {10675027},
journal = {Journal of the American Medical Informatics Association},
number = {5},
pages = {576--586},
pmid = {15905486},
title = {{ALICE: An algorithm to extract abbreviations from MEDLINE}},
volume = {12},
year = {2005}
}
@article{Yarygina2012,
abstract = {This paper addresses the problem of extracting acronyms and their definitions from large documents in a setting, when high recall is required and user feedback is available. We propose a three step approach to deal with the problem. First, acronym candidates are extracted using a weak regular expression. This step results in a list of acronyms with high recall but low precision rates. Second, definitions are constructed for every acronym candidate from its surrounding text. And last, a classifier is used to select genuine acronymdefinition pairs. At the last step we use relevance feedback mechanism to tune the classifier model for every particular document. This allows achieving reasonable precision without losing recall. As opposed to existing approaches, either created to be generic and domain independent or tuned to one particular domain, our method is adaptive to an input document. We evaluate the proposed approach using three datasets from different domains. The experiments prove the validity of the presented ideas. Copyright 2012 ACM.},
author = {Yarygina, Anna and Vassilieva, Natalia},
doi = {10.1145/2320765.2320781},
file = {:D\:/University/Thesis/Research/2320765.2320781.pdf:pdf},
isbn = {9781450311434},
journal = {ACM International Conference Proceeding Series},
pages = {21--28},
title = {{High-recall extraction of acronym-definition pairs with relevance feedback}},
year = {2012}
}
@article{Carli2003,
author = {Carli, Don},
file = {:D\:/University/Thesis/Research/le14.pdf:pdf},
issn = {10968520},
journal = {Print on Demand},
number = {2},
pages = {42},
title = {{Honk If You Support JDF}},
volume = {9},
year = {2003}
}
@article{Li2021,
abstract = {Acronym disambiguation means finding the correct meaning of an ambiguous acronym from the dictionary in a given sentence, which is one of the key points for scientific document understanding (SDU@AAAI-22). Recently, many attempts have tried to solve this problem via fine-tuning the pre-trained masked language models (MLMs) in order to obtain a better acronym representation. However, the acronym meaning is varied under different contexts, whose corresponding phrase representation mapped in different directions lacks discrimination in the entire vector space. Thus, the original representations of the pre-trained MLMs are not ideal for the acronym disambiguation task. In this paper, we propose a Simple framework for Contrastive Learning of Acronym Disambiguation (SimCLAD) method to better understand the acronym meanings. Specifically, we design a continual contrastive pre-training method that enhances the pre-trained model's generalization ability by learning the phrase-level contrastive distributions between true meaning and ambiguous phrases. The results on the acronym disambiguation of the scientific domain in English show that the proposed method outperforms all other competitive state-of-the-art (SOTA) methods.},
archivePrefix = {arXiv},
arxivId = {2111.14306},
author = {Li, Bin and Xia, Fei and Weng, Yixuan and Huang, Xiusheng and Sun, Bin},
eprint = {2111.14306},
file = {:D\:/University/Thesis/Research/SimCLAD- A Simple Framework for Contrastive Learning of.pdf:pdf},
title = {{SimCLAD: A Simple Framework for Contrastive Learning of Acronym Disambiguation}},
url = {http://arxiv.org/abs/2111.14306},
year = {2021}
}
@article{Pan2021,
abstract = {Acronym disambiguation (AD) task aims to find the correct expansions of an ambiguous ancronym in a given sentence. Although it is convenient to use acronyms, sometimes they could be difficult to understand. Identifying the appropriate expansions of an acronym is a practical task in natural language processing. Since few works have been done for AD in scientific field, we propose a binary classification model incorporating BERT and several training strategies including dynamic negative sample selection, task adaptive pretraining, adversarial training and pseudo labeling in this paper. Experiments on SciAD show the effectiveness of our proposed model and our score ranks 1st in SDU@AAAI-21 shared task 2: Acronym Disambiguation.},
archivePrefix = {arXiv},
arxivId = {2103.00488},
author = {Pan, Chunguang and Song, Bingyan and Wang, Shengguang and Luo, Zhipeng},
eprint = {2103.00488},
file = {:D\:/University/Thesis/Research/BERT-based Acronym Disambiguation with Multiple Training Strategies.pdf:pdf},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
title = {{BERT-based acronym disambiguation with multiple training strategies}},
volume = {2831},
year = {2021}
}
@article{Freeling2019,
author = {Freeling, Benjamin and Doubleday, Zo{\"{e}} A. and Connell, Sean D.},
doi = {10.1073/pnas.1819937116},
file = {:D\:/University/Thesis/Research/How can we boost the impact of publications Try better writing.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {2},
pages = {341--343},
pmid = {30622212},
title = {{How can we boost the impact of publications? Try better writing}},
volume = {116},
year = {2019}
}
@article{Zhao2019,
abstract = {PURPOSE A substantial portion of medical data is unstructured. Extracting data from unstructured text presents a barrier to advancing clinical research and improving patient care. In addition, ongoing studies have been focused predominately on the English language, whereas inflected languages with non-Latin alphabets (such as Slavic languages with a Cyrillic alphabet) present numerous linguistic challenges. We developed deep-learning-based natural language processing algorithms for automatically extracting biomarker status of patients with breast cancer from three oncology centers in Bulgaria. METHODS We used dual embeddings for English and Bulgarian languages, encoding both syntactic and polarity information for the words. The embeddings were subsequently aligned so that they were in the same vector space. The embeddings were used as input to convolutional or recurrent neural networks to derive the biomarker status of estrogen receptor, progesterone receptor, and human epidermal growth factor receptor 2. RESULTS We showed that we can resolve ambiguity in highly variable medical text containing both Latin and Cyrillic text. Final models incorporating both English and Bulgarian syntax and polarity embeddings achieved F1 scores of 0.90 or higher for all estrogen receptor, progesterone receptor, and human epidermal growth factor receptor 2 biomarkers. The models were robust against human errors originally found in the training set. In addition, such models can be extended for analyzing text containing words not seen during training. CONCLUSION By using several techniques that incorporate dual-word embeddings encoding syntactic and polarity information in two languages followed by deep neural network architectures, we show that researchers can extract and normalize parameters within medical data. The principles described here can be used to analyze Cyrillic or Latin mixed medical text and extract other parameters.},
author = {Zhao, Boyang},
doi = {10.1200/cci.19.00057},
file = {:D\:/University/Thesis/Research/Clinical Data Extraction and Normalization of Cyrillic electronic health records via Deep-learning natural language processing.pdf:pdf},
issn = {2473-4276},
journal = {JCO Clinical Cancer Informatics},
number = {3},
pages = {1--9},
pmid = {31577448},
title = {{Clinical Data Extraction and Normalization of Cyrillic Electronic Health Records Via Deep-Learning Natural Language Processing}},
year = {2019}
}
@article{SaneeshMohammed2013,
abstract = {This paper deals with the problem of extracting acronym-definition pairs from biomedical text. We propose an improved Text mining system based on pattern matching method and space reduction heuristics which increases both recall and precision. Three metrics were used for evaluating the system - recall (measure of how much relevant data the system has extracted from text), precision (measure of how much data returned by the system is actually correct) and f-factor (combined value of recall and precision). Experimental results achieved 98.68% recall and 98.68% precision. {\textcopyright} 2013 IEEE.},
author = {{Saneesh Mohammed}, N. and Nazeer, K. A.Abdul},
doi = {10.1109/ICCC.2013.6731649},
file = {:D\:/University/Thesis/Research/Saneesh-Mohammedn - An Improved Method for Extracting.pdf:pdf},
isbn = {9781479905751},
journal = {2013 International Conference on Control Communication and Computing, ICCC 2013},
number = {Iccc},
pages = {194--197},
title = {{An improved method for extracting acronym-definition pairs from biomedical Literature}},
year = {2013}
}
@article{Plaven-Sigray2017,
abstract = {Clarity and accuracy of reporting are fundamental to the scientific process. Readability formulas can estimate how difficult a text is to read. Here, in a corpus consisting of 709,577 abstracts published between 1881 and 2015 from 123 scientific journals, we show that the readability of science is steadily decreasing. Our analyses show that this trend is indicative of a growing use of general scientific jargon. These results are concerning for scientists and for the wider public, as they impact both the reproducibility and accessibility of research findings.},
author = {Plav{\'{e}}n-Sigray, Pontus and Matheson, Granville James and Schiffler, Bj{\"{o}}rn Christian and Thompson, William Hedley},
doi = {10.7554/eLife.27725},
file = {:D\:/University/Thesis/Research/The readability of scientific texts is decreasing over time.pdf:pdf},
issn = {2050084X},
journal = {eLife},
pages = {1--14},
pmid = {28873054},
title = {{The readability of scientific texts is decreasing over time}},
volume = {6},
year = {2017}
}
@article{Mikolov2013,
abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
archivePrefix = {arXiv},
arxivId = {1310.4546},
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
eprint = {1310.4546},
file = {:D\:/University/Thesis/Research/Acronym Disambiguation Using Word Embedding.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {4178--4179},
title = {{Distributed representations ofwords and phrases and their compositionality}},
year = {2013}
}
@article{Appelman2021,
abstract = {Through two experiments (N1 = 131, N 2 = 520), this study looks at whether the negative effects of acronyms and abbreviations in headlines are based on their presence or their difficulty. In all, it finds support for a difficulty effect; people had lower content and source perceptions when they were shown a headline with unfamiliar acronym(s) compared with ones they knew, and they were more frustrated with those articles. These differences were moderated by need for cognition. In terms of a presence effect, people did perceive some differences in articles with acronyms in their headlines compared to those without, particularly if they were paying close attention, but those differences were much less pronounced. In other words, readers don't seem to be inherently bothered by the presence of acronyms in headlines; they seem to be bothered by the ones they don't understand. These findings suggest that journalists should strive to explain acronyms and abbreviations in headlines, rather than worry about avoiding them altogether. Implications for journalistic practice, reader engagement, and dual-processing theories of persuasion are discussed.},
author = {Appelman, Alyssa},
doi = {10.1080/17512786.2020.1867622},
file = {:D\:/University/Thesis/Research/Written in Code Exploring the Negative Effects of Acronyms in News Headlines.pdf:pdf},
issn = {17512794},
journal = {Journalism Practice},
keywords = {Acronyms,abbreviations,cognition,experimental design,headlines,perception},
number = {0},
pages = {1--17},
publisher = {Taylor & Francis},
title = {{Written in Code: Exploring the Negative Effects of Acronyms in News Headlines}},
url = {https://doi.org/10.1080/17512786.2020.1867622},
volume = {0},
year = {2021}
}
@article{Devlin2019,
abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
archivePrefix = {arXiv},
arxivId = {1810.04805},
author = {Devlin, Jacob and Chang, Ming Wei and Lee, Kenton and Toutanova, Kristina},
eprint = {1810.04805},
file = {:D\:/University/Thesis/uva-thesis-repository/research/BERT- Pre-training of Deep Bidirectional Transformers for Language Understanding. Computing Research Repository.pdf:pdf},
isbn = {9781950737130},
journal = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
number = {Mlm},
pages = {4171--4186},
title = {{BERT: Pre-training of deep bidirectional transformers for language understanding}},
volume = {1},
year = {2019}
}
@article{Lisboa,
author = {Lisboa, I S T Universidade De and Galhardas, Helena},
file = {:D\:/University/Thesis/Research/AcX system, techniques, and experiments for Acronym.pdf:pdf},
title = {{AcX : system , techniques , and experiments for Acronym eXpansion [ Experiments , Analysis & Benchmarks ]}}
}
@article{Veyseh2021,
abstract = {Acronyms and abbreviations are the short-form of longer phrases and they are ubiquitously employed in various types of writing. Despite their usefulness to save space in writing and time in reading, they also provide challenges for understanding the text especially if the acronym is not defined in the text or if it is used far from its definition in long texts. To alleviate this issue, there are considerable efforts both from the research community and software developers to build systems for identifying acronyms and finding their correct meanings in the text. However, none of the existing works provide a unified solution capable of processing acronyms in various domains and to be publicly available. Thus, we introduce MadDog, the first web-based acronym identification and disambiguation system which can process acronyms from various domains including scientific, biomedical, and general domains. The web-based system is publicly available at http://iq.cs.uoregon.edu: 5000 and a demo video is available at https://youtu.be/IkSh7LqI42M. The system source code is also available at https://github.com/amirveyseh/MadDog.},
archivePrefix = {arXiv},
arxivId = {2101.09893},
author = {Veyseh, Amir Pouran Ben and Dernoncourt, Franck and Chang, Walter and Nguyen, Thien Huu},
doi = {10.18653/v1/2021.eacl-demos.20},
eprint = {2101.09893},
file = {:D\:/University/Thesis/Research/MadDog - A web-based system for acronym identification and disambiguation.pdf:pdf},
isbn = {9781954085053},
journal = {EACL 2021 - 16th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the System Demonstrations},
pages = {160--167},
title = {{MadDog: A web-based system for acronym identification and disambiguation}},
year = {2021}
}
@article{PouranBenVeyseh2021,
abstract = {Acronyms are the short forms of phrases that facilitate conveying lengthy sentences in documents and serve as one of the mainstays of writing. Due to their importance, identifying acronyms and corresponding phrases (i.e., acronym identification (AI)) and finding the correct meaning of each acronym (i.e., acronym disambiguation (AD)) are crucial for text understanding. Despite the recent progress on this task, there are some limitations in the existing datasets which hinder further improvement. More specifically, limited size of manually annotated AI datasets or noises in the automatically created acronym identification datasets obstruct designing advanced high-performing acronym identification models. Moreover, the existing datasets are mostly limited to the medical domain and ignore other domains. In order to address these two limitations, we first create a manually annotated large AI dataset for scientific domain. This dataset contains 17,506 sentences which is substantially larger than previous scientific AI datasets. Next, we prepare an AD dataset for scientific domain with 62,441 samples which is significantly larger than the previous scientific AD dataset. Our experiments show that the existing state-of-the-art models fall far behind human-level performance on both datasets proposed by this work. In addition, we propose a new deep learning model that utilizes the syntactical structure of the sentence to expand an ambiguous acronym in a sentence. The proposed model outperforms the state-of-the-art models on the new AD dataset, providing a strong baseline for future research on this dataset.},
archivePrefix = {arXiv},
arxivId = {2010.14678},
author = {{Pouran Ben Veyseh}, Amir and Dernoncourt, Franck and Tran, Quan Hung and Nguyen, Thien Huu},
doi = {10.18653/v1/2020.coling-main.292},
eprint = {2010.14678},
file = {:D\:/University/Thesis/Research/What Does This Acronym Mean Introducing a New Dataset for Acronym Identification adn Disambiguation.pdf:pdf},
pages = {3285--3301},
title = {{What Does This Acronym Mean? Introducing a New Dataset for Acronym Identification and Disambiguation}},
year = {2021}
}
@article{Schwartz2003,
abstract = {The volume of biomedical text is growing at a fast rate, creating challenges for humans and computer systems alike. One of these challenges arises from the frequent use of novel abbreviations in these texts, thus requiring that biomedical lexical ontologies be continually updated. In this paper we show that the problem of identifying abbreviations' definitions can be solved with a much simpler algorithm than that proposed by other research efforts. The algorithm achieves 96% precision and 82% recall on a standard test collection, which is at least as good as existing approaches. It also achieves 95% precision and 82% recall on another, larger test set. A notable advantage of the algorithm is that, unlike other approaches, it does not require any training data.},
author = {Schwartz, Ariel S. and Hearst, Marti A.},
doi = {10.1142/9789812776303_0042},
file = {:D\:/University/Thesis/Research/Schwartz - A SIMPLE ALGORITHM FOR IDENTIFYING ABBREVIATION.pdf:pdf},
issn = {2335-6928},
journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
pages = {451--462},
pmid = {12603049},
title = {{A simple algorithm for identifying abbreviation definitions in biomedical text.}},
year = {2003}
}
@article{Cherecharov2017,
abstract = {The wide use of web-based information systems and a lack of highly skilled developers are the primary motivation to search for methods and approaches to optimize the building of such systems. This paper describes a model for creating web-based information systems by using a core of reusable, independent, and installable base modules. Such a system is easily adapted to a client{\^{a}}€™s needs and is extendable by adding specific modules that interact with the remainder of the system by following certain rules. The approach allows flexible and rapid development of applications for small to extremely large web-based systems, simply by adding modules with adequate functionality. The growing demand of Bulgarian customers for such systems is the reason for building a base module for automatic processing of Bulgarian text. This paper presents a module that performs automatic morphological analysis and synthesis, verifies syntactic agreement, automatically places stress, and processes complex verb forms, among other functions. The described functionality can be integrated with other modules using a suitable interface},
author = {Cherecharov, Stoyan and Krushkov, Hristo and Krushkova, Mariana},
doi = {10.12955/cbup.v5.1080},
file = {:D\:/University/Thesis/Research/NLP MODULE FOR BULGARIAN TEXT PROCESSING.pdf:pdf},
issn = {1805-997X},
journal = {CBU International Conference Proceedings},
keywords = {computational linguistics,natural language processing,software modules,web-based systems},
pages = {1113--1117},
title = {{Nlp Module for Bulgarian Text Processing}},
volume = {5},
year = {2017}
}
@article{Simov2002,
abstract = {In the field of Human Language Technology (HLT), the existence of linguistically interpreted real-world texts provides the license necessary for a given language to enter the area of high-tech applications. The significance of Bul Tree Bank is the granting of an HLT license to a "less processed" language like Bulgarian which, until recently, has been formally modelled and processed mainly on the morphology level. The Bul Tree Bank project aims at the creation of syntactically annotated data for Bulgarian and the tools for their production, management and automatic processing. It provides not only language resources, but develops an infrastructure of research solutions, production scenarios and services.},
author = {Simov, Kiril and Osenova, Petya and Slavcheva, Milena and Kolkovska, Sia and Balabanova, Elisaveta and Doikoff, Dimitar and Ivanova, Krassimira and Simov, Alexander and Kouylekov, Milen},
file = {:D\:/University/Thesis/Research/Building a Linguistically Interpreted Corpus of Bulgarian the BulTreeBank.pdf:pdf},
journal = {Proceedings of the 3rd International Conference on Language Resources and Evaluation, LREC 2002},
pages = {1729--1736},
title = {{Building a linguistically interpreted corpus of Bulgarian: The bul tree bank}},
year = {2002}
}
@article{Charbonnier2018,
abstract = {Scientific papers from all disciplines contain many abbreviations and acronyms. In many cases these acronyms are ambiguous. We present a method to choose the contextual correct definition of an acronym that does not require training for each acronym and thus can be applied to a large number of different acronyms with only few instances. We constructed a set of 19,954 examples of 4,365 ambiguous acronyms from image captions in scientific papers along with their contextually correct definition from different domains. We learn word embeddings for all words in the corpus and compare the averaged context vector of the words in the expansion of an acronym with the weighted average vector of the words in the context of the acronym. We show that this method clearly outperforms (classical) cosine similarity. Furthermore, we show that word embeddings learned from a 1 billion word corpus of scientific texts outperform word embeddings learned from much larger general corpora.},
author = {Charbonnier, Jean and Wartena, Christian},
file = {:D\:/University/Thesis/Research/Using Word Embeddings for Unsupervised Acronym Disambiguation.pdf:pdf},
isbn = {9781948087506},
journal = {COLING 2018 - 27th International Conference on Computational Linguistics, Proceedings},
pages = {2610--2619},
title = {{Using word embeddings for unsupervised acronym disambiguation}},
year = {2018}
}
@article{Kapukaranov2015,
abstract = {We present a system for fine-grained sentiment analysis in Bulgarian movie reviews. As this is pioneering work for this combination of language and sentiment granularity, we create suitable, freely available resources: a dataset of movie reviews with fine-grained scores, and a sentiment polarity lexicon. We further compare experimentally the performance of classification, regression and ordinal regression in a 3-way, 5-way and 11-way classification setups, using as features not only the text from the reviews, but also contextual information in the form of metadata, e.g., movie length, director, actors, genre, country, and various scores: IMDB, Cinexio, and user-average. The results show that adding contextual information yields strong performance gains.},
author = {Kapukaranov, Borislav and Nakov, Preslav},
file = {:D\:/University/Thesis/Research/R15-1036.pdf:pdf},
issn = {13138502},
journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
pages = {266--274},
title = {{Fine-grained sentiment analysis for movie reviews in Bulgarian}},
volume = {2015-Janua},
year = {2015}
}
@article{Beltagy2020,
abstract = {Obtaining large-scale annotated data for NLP tasks in the scientific domain is challenging and expensive. We release SCIBERT, a pretrained language model based on BERT (Devlin et al., 2019) to address the lack of high-quality, large-scale labeled scientific data. SCIBERT leverages unsupervised pretraining on a large multi-domain corpus of scientific publications to improve performance on downstream scientific NLP tasks. We evaluate on a suite of tasks including sequence tagging, sentence classification and dependency parsing, with datasets from a variety of scientific domains. We demonstrate statistically significant improvements over BERT and achieve new state-of-the-art results on several of these tasks. The code and pretrained models are available at https://github.com/allenai/scibert/.},
archivePrefix = {arXiv},
arxivId = {1903.10676},
author = {Beltagy, Iz and Lo, Kyle and Cohan, Arman},
doi = {10.18653/v1/d19-1371},
eprint = {1903.10676},
file = {:D\:/University/Thesis/Research/1903.10676.pdf:pdf},
isbn = {9781950737901},
journal = {EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
pages = {3615--3620},
title = {{SCIBERT: A pretrained language model for scientific text}},
year = {2020}
}
@article{Cortes1995,
author = {Cortes, Corinna and Vapnik, Vladimir},
doi = {10.1007/BF00994018},
file = {:D\:/University/Thesis/Research/Cortes-Vapnik1995_Article_Support-vectorNetworks.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
month = {sep},
number = {3},
pages = {273--297},
title = {{Support-vector networks}},
url = {http://link.springer.com/10.1007/BF00994018},
volume = {20},
year = {1995}
}
@article{Sohn2008,
abstract = {Background: The rapid growth of biomedical literature presents challenges for automatic text processing, and one of the challenges is abbreviation identification. The presence of unrecognized abbreviations in text hinders indexing algorithms and adversely affects information retrieval and extraction. Automatic abbreviation definition identification can help resolve these issues. However, abbreviations and their definitions identified by an automatic process are of uncertain validity. Due to the size of databases such as MEDLINE only a small fraction of abbreviation-definition pairs can be examined manually. An automatic way to estimate the accuracy of abbreviation-definition pairs extracted from text is needed. In this paper we propose an abbreviation definition identification algorithm that employs a variety of strategies to identify the most probable abbreviation definition. In addition our algorithm produces an accuracy estimate, pseudo-precision, for each strategy without using a human-judged gold standard. The pseudo-precisions determine the order in which the algorithm applies the strategies in seeking to identify the definition of an abbreviation. Results: On the Medstract corpus our algorithm produced 97% precision and 85% recall which is higher than previously reported results. We also annotated 1250 randomly selected MEDLINE records as a gold standard. On this set we achieved 96.5% precision and 83.2% recall. This compares favourably with the well known Schwartz and Hearst algorithm. Conclusion: We developed an algorithm for abbreviation identification that uses a variety of strategies to identify the most probable definition for an abbreviation and also produces an estimated accuracy of the result. This process is purely automatic. {\textcopyright} 2008 Sohn et al; licensee BioMed Central Ltd.},
author = {Sohn, Sunghwan and Comeau, Donald C. and Kim, Won and Wilbur, John W.},
doi = {10.1186/1471-2105-9-402},
file = {:D\:/University/Thesis/Research/Abbreviation definition identification based on automatic precision.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
pages = {1--10},
pmid = {18817555},
title = {{Abbreviation definition identification based on automatic precision estimates}},
volume = {9},
year = {2008}
}
@article{AleksandarSavkov2011,
abstract = {In this paper, we present a web-based morphosyntactic module for Bulgarian, which includes a statistical tagger and a lemmatizer. Both tools are implemented as a pipeline, which comprises an SVM-based tagger, a lexicon look-up component, a set of morphosyntactic context rules and a lemmatizer. The input and output of each component is defined according to the WebLicht format. Thus, ensuring a better workflow and compatibility with other NLP architectures for Bulgarian and other wellprocessed languages.},
author = {{Aleksandar Savkov}, Laska Laskova, Petya Osenova, and {Kiril Simov}, and Stanislava Kancheva},
file = {:D\:/University/Thesis/Research/A_Web-based_Morphological_Tagger_for_Bulgarian.pdf:pdf},
journal = {Natural Language Processing, Multilinguality},
keywords = {Bulgarian,EuroMatrixPlus,SVMTool,TCF,WebLicht,morphological analysis},
number = {November 2014},
pages = {126--137},
title = {{A Web-based Morphological Tagger for Bulgarian}},
url = {http://www.aleksandar.savkov.eu/docs/publications/morph.pdf},
year = {2011}
}
@article{Radev2019,
abstract = {This paper discusses some possible usages of one unexplored lexical language resource containing Bulgarian verb paradigms and their English translations. This type of data can be used for machine translation, generation of pseudo corpora/language exercises, and evaluation of parsers. Upon completion, the resource will be linked with other existing resources such as the morphological lexicon, valency lexicon, as well as BTB-WordNet.},
author = {Radev, Ivaylo},
doi = {10.26615/issn.2603-2821.2019_012},
file = {:D\:/University/Thesis/Research/R19-2012.pdf:pdf},
pages = {76--82},
title = {{Adding Linguistic Knowledge to NLP Tasks for Bulgarian: The Verb Paradigm Patterns}},
year = {2019}
}
@article{Li2018,
abstract = {Acronyms are abbreviations formed from the initial components of words or phrases. In enterprises, people often use acronyms to make communications more efficient. However, acronyms could be difficult to understand for people who are not familiar with the subject matter (new employees, etc.), thereby affecting productivity. To alleviate such troubles, we study how to automatically resolve the true meanings of acronyms in a given context. Acronym disambiguation for enterprises is challenging for several reasons. First, acronyms may be highly ambiguous since an acronym used in the enterprise could have multiple internal and external meanings. Second, there are usually no comprehensive knowledge bases such as Wikipedia available in enterprises. Finally, the system should be generic to work for any enterprise. In this work we propose an end-to-end framework to tackle all these challenges. The framework takes the enterprise corpus as input and produces a high-quality acronym disambiguation system as output. Our disambiguation models are trained via distant supervised learning, without requiring any manually labeled training examples. Therefore, our proposed framework can be deployed to any enterprise to support high-quality acronym disambiguation. Experimental results on real world data justified the effectiveness of our system.},
author = {Li, Yang and Zhao, Bo and Fuxman, Ariel and Tao, Fangbo},
doi = {10.18653/v1/p18-1121},
file = {:D\:/University/Thesis/Research/P18-1121.pdf:pdf},
isbn = {9781948087322},
journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
pages = {1308--1317},
title = {{Guess me if you can: Acronym disambiguation for enterprises}},
volume = {1},
year = {2018}
}
@article{Kuo2009,
abstract = {Background: To automatically process large quantities of biological literature for knowledge discovery and information curation, text mining tools are becoming essential. Abbreviation recognition is related to NER and can be considered as a pair recognition task of a terminology and its corresponding abbreviation from free text. The successful identification of abbreviation and its corresponding definition is not only a prerequisite to index terms of text databases to produce articles of related interests, but also a building block to improve existing gene mention tagging and gene normalization tools. Results: Our approach to abbreviation recognition (AR) is based on machine-learning, which exploits a novel set of rich features to learn rules from training data. Tested on the AB3P corpus, our system demonstrated a F-score of 89.90% with 95.86% precision at 84.64% recall, higher than the result achieved by the existing best AR performance system. We also annotated a new corpus of 1200 PubMed abstracts which was derived from BioCreative II gene normalization corpus. On our annotated corpus, our system achieved a F-score of 86.20% with 93.52% precision at 79.95% recall, which also outperforms all tested systems. Conclusion: By applying our system to extract all short form-long form pairs from all available PubMed abstracts, we have constructed BIOADI. Mining BIOADI reveals many interesting trends of bio-medical research. Besides, we also provide an off-line AR software in the download section on http://bioagent.iis.sinica.edu.tw/BIOADI/. {\textcopyright} 2009 Kuo et al; licensee BioMed Central Ltd.},
author = {Kuo, Cheng Ju and Ling, Maurice H.T. and Lin, Kuan Ting and Hsu, Chun Nan},
doi = {10.1186/1471-2105-10-S15-S7},
file = {:D\:/University/Thesis/Research/BIOADI a machine learning approach to identifying abbreviations.pdf:pdf},
isbn = {1471210510},
issn = {14712105},
journal = {BMC Bioinformatics},
number = {SUPPL. 15},
pages = {1--10},
pmid = {19958517},
title = {{BIOADI: A machine learning approach to identifying abbreviations and definitions in biological literature}},
volume = {10},
year = {2009}
}
@misc{Pustejovsky2001,
abstract = {Acronyms are widely used in biomedical and other technical texts. Understanding their meaning constitutes an important problem in the automatic extraction and mining of information from text. Here we present a system called ACROMED that is part of a set of Information Extraction tools designed for processing and extracting information from abstracts in the Medline database. In this paper, we present the results of two strategies for finding the long forms for acronyms in biomedical texts. These strategies differ from previous automated acronym extraction methods by being tuned to the complex phrase structures of the biomedical lexicon and by incorporating shallow parsing of the text into the acronym recognition algorithm. The performance of our system was tested with several data sets obtaining a performance of 72 % recall with 97 % precision. These results are found to be better for biomedical texts than the performance of other acronym extraction systems designed for unrestricted text. {\textcopyright} 2001 IMIA. All right reserved.},
author = {Pustejovsky, James and Casta{\~{n}}o, Jos{\'{e}} and Cochran, Brent and Kotecki, Maciej and Morrell, Michael},
booktitle = {Studies in Health Technology and Informatics},
doi = {10.3233/978-1-60750-928-8-371},
file = {:D\:/University/Thesis/Research/Pustejovsky - Automatic extraction of acronym-meaning pairs from MEDLINE databases..pdf:pdf},
isbn = {1586031945},
issn = {18798365},
keywords = {Abstracting and Indexing,Acronyms,Information Storage and Retrieval,Medical Informatics,Medline,Pattern recognition},
pages = {371--375},
pmid = {11604766},
title = {{Automatic extraction of acronym-meaning Pairs from MEDLINE databases}},
volume = {84},
year = {2001}
}
@article{Barnett2020,
abstract = {Some acronyms are useful and are widely understood, but many of the acronyms used in scientific papers hinder understanding and contribute to the increasing fragmentation of science. Here we report the results of an analysis of more than 24 million article titles and 18 million article abstracts published between 1950 and 2019. There was at least one acronym in 19% of the titles and 73% of the abstracts. Acronym use has also increased over time, but the re-use of acronyms has declined. We found that from more than one million unique acronyms in our data, just over 2,000 (0.2%) were used regularly, and most acronyms (79%) appeared fewer than 10 times. Acronyms are not the biggest current problem in science communication, but reducing their use is a simple change that would help readers and potentially increase the value of science.},
author = {Barnett, Adrian and Doubleday, Zoe},
doi = {10.7554/eLife.60080},
file = {:D\:/University/Thesis/Research/Meta research - The growth of acronyms in the.pdf:pdf},
issn = {2050084X},
journal = {eLife},
pages = {1--10},
pmid = {32701448},
title = {{The growth of acronyms in the scientific literature}},
volume = {9},
year = {2020}
}
